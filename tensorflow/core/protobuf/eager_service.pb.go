// Code generated by protoc-gen-go. DO NOT EDIT.
// source: github.com/smoug25/tensorflow_serving_helper/tensorflow/core/protobuf/eager_service.proto

package protobuf

import (
	context "context"
	fmt "fmt"
	proto "github.com/golang/protobuf/proto"
	framework "github.com/smoug25/tensorflow_serving_helper/tensorflow/core/framework"
	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
	math "math"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.ProtoPackageIsVersion3 // please upgrade the proto package

// A proto representation of an eager operation.
type Operation struct {
	// A unique identifier for the operation. Set by the client so that the client
	// can uniquely identify the outputs of the scheduled operation.
	//
	// In the initial implementation, sending duplicate IDs has undefined
	// behaviour, but additional constraints may be placed upon this in the
	// future.
	Id     int64                           `protobuf:"varint,1,opt,name=id,proto3" json:"id,omitempty"`
	Name   string                          `protobuf:"bytes,2,opt,name=name,proto3" json:"name,omitempty"`
	Inputs []*framework.RemoteTensorHandle `protobuf:"bytes,3,rep,name=inputs,proto3" json:"inputs,omitempty"`
	// Control Operation IDs that will be respected when ops are re-ordered by
	// async execution. If async execution (+ op re-ordering) is not enabled, this
	// should have no effect.
	ControlOpIds []int64                         `protobuf:"varint,4,rep,packed,name=control_op_ids,json=controlOpIds,proto3" json:"control_op_ids,omitempty"`
	Attrs        map[string]*framework.AttrValue `protobuf:"bytes,5,rep,name=attrs,proto3" json:"attrs,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	Device       string                          `protobuf:"bytes,6,opt,name=device,proto3" json:"device,omitempty"`
	// Indicates whether the op is a component of a multi-device function.
	IsComponentFunction bool `protobuf:"varint,7,opt,name=is_component_function,json=isComponentFunction,proto3" json:"is_component_function,omitempty"`
	// Set when is_component_function is true. It's initially generated
	// when we create an FunctionLibraryRuntime::Options (negative value) and used
	// to create Rendezvous for function execution. All components of a
	// multi-device function should use the same step id to make sure that they
	// can communicate through Send/Recv ops.
	FuncStepId int64 `protobuf:"varint,8,opt,name=func_step_id,json=funcStepId,proto3" json:"func_step_id,omitempty"`
	// Indicates whether the op is a function.
	IsFunction           bool     `protobuf:"varint,9,opt,name=is_function,json=isFunction,proto3" json:"is_function,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *Operation) Reset()         { *m = Operation{} }
func (m *Operation) String() string { return proto.CompactTextString(m) }
func (*Operation) ProtoMessage()    {}
func (*Operation) Descriptor() ([]byte, []int) {
	return fileDescriptor_7c18508aed02748c, []int{0}
}

func (m *Operation) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_Operation.Unmarshal(m, b)
}
func (m *Operation) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_Operation.Marshal(b, m, deterministic)
}
func (m *Operation) XXX_Merge(src proto.Message) {
	xxx_messageInfo_Operation.Merge(m, src)
}
func (m *Operation) XXX_Size() int {
	return xxx_messageInfo_Operation.Size(m)
}
func (m *Operation) XXX_DiscardUnknown() {
	xxx_messageInfo_Operation.DiscardUnknown(m)
}

var xxx_messageInfo_Operation proto.InternalMessageInfo

func (m *Operation) GetId() int64 {
	if m != nil {
		return m.Id
	}
	return 0
}

func (m *Operation) GetName() string {
	if m != nil {
		return m.Name
	}
	return ""
}

func (m *Operation) GetInputs() []*framework.RemoteTensorHandle {
	if m != nil {
		return m.Inputs
	}
	return nil
}

func (m *Operation) GetControlOpIds() []int64 {
	if m != nil {
		return m.ControlOpIds
	}
	return nil
}

func (m *Operation) GetAttrs() map[string]*framework.AttrValue {
	if m != nil {
		return m.Attrs
	}
	return nil
}

func (m *Operation) GetDevice() string {
	if m != nil {
		return m.Device
	}
	return ""
}

func (m *Operation) GetIsComponentFunction() bool {
	if m != nil {
		return m.IsComponentFunction
	}
	return false
}

func (m *Operation) GetFuncStepId() int64 {
	if m != nil {
		return m.FuncStepId
	}
	return 0
}

func (m *Operation) GetIsFunction() bool {
	if m != nil {
		return m.IsFunction
	}
	return false
}

type QueueItem struct {
	// The remote executor should be able to handle either executing ops directly,
	// or releasing any unused tensor handles, since the tensor lifetime is
	// maintained by the client.
	//
	// Types that are valid to be assigned to Item:
	//	*QueueItem_HandleToDecref
	//	*QueueItem_Operation
	//	*QueueItem_SendTensor
	//	*QueueItem_RegisterFunction
	//	*QueueItem_CleanupFunction
	Item                 isQueueItem_Item `protobuf_oneof:"item"`
	XXX_NoUnkeyedLiteral struct{}         `json:"-"`
	XXX_unrecognized     []byte           `json:"-"`
	XXX_sizecache        int32            `json:"-"`
}

func (m *QueueItem) Reset()         { *m = QueueItem{} }
func (m *QueueItem) String() string { return proto.CompactTextString(m) }
func (*QueueItem) ProtoMessage()    {}
func (*QueueItem) Descriptor() ([]byte, []int) {
	return fileDescriptor_7c18508aed02748c, []int{1}
}

func (m *QueueItem) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_QueueItem.Unmarshal(m, b)
}
func (m *QueueItem) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_QueueItem.Marshal(b, m, deterministic)
}
func (m *QueueItem) XXX_Merge(src proto.Message) {
	xxx_messageInfo_QueueItem.Merge(m, src)
}
func (m *QueueItem) XXX_Size() int {
	return xxx_messageInfo_QueueItem.Size(m)
}
func (m *QueueItem) XXX_DiscardUnknown() {
	xxx_messageInfo_QueueItem.DiscardUnknown(m)
}

var xxx_messageInfo_QueueItem proto.InternalMessageInfo

type isQueueItem_Item interface {
	isQueueItem_Item()
}

type QueueItem_HandleToDecref struct {
	HandleToDecref *framework.RemoteTensorHandle `protobuf:"bytes,1,opt,name=handle_to_decref,json=handleToDecref,proto3,oneof"`
}

type QueueItem_Operation struct {
	Operation *Operation `protobuf:"bytes,2,opt,name=operation,proto3,oneof"`
}

type QueueItem_SendTensor struct {
	SendTensor *SendTensorOp `protobuf:"bytes,3,opt,name=send_tensor,json=sendTensor,proto3,oneof"`
}

type QueueItem_RegisterFunction struct {
	RegisterFunction *RegisterFunctionOp `protobuf:"bytes,4,opt,name=register_function,json=registerFunction,proto3,oneof"`
}

type QueueItem_CleanupFunction struct {
	CleanupFunction *CleanupFunctionOp `protobuf:"bytes,5,opt,name=cleanup_function,json=cleanupFunction,proto3,oneof"`
}

func (*QueueItem_HandleToDecref) isQueueItem_Item() {}

func (*QueueItem_Operation) isQueueItem_Item() {}

func (*QueueItem_SendTensor) isQueueItem_Item() {}

func (*QueueItem_RegisterFunction) isQueueItem_Item() {}

func (*QueueItem_CleanupFunction) isQueueItem_Item() {}

func (m *QueueItem) GetItem() isQueueItem_Item {
	if m != nil {
		return m.Item
	}
	return nil
}

func (m *QueueItem) GetHandleToDecref() *framework.RemoteTensorHandle {
	if x, ok := m.GetItem().(*QueueItem_HandleToDecref); ok {
		return x.HandleToDecref
	}
	return nil
}

func (m *QueueItem) GetOperation() *Operation {
	if x, ok := m.GetItem().(*QueueItem_Operation); ok {
		return x.Operation
	}
	return nil
}

func (m *QueueItem) GetSendTensor() *SendTensorOp {
	if x, ok := m.GetItem().(*QueueItem_SendTensor); ok {
		return x.SendTensor
	}
	return nil
}

func (m *QueueItem) GetRegisterFunction() *RegisterFunctionOp {
	if x, ok := m.GetItem().(*QueueItem_RegisterFunction); ok {
		return x.RegisterFunction
	}
	return nil
}

func (m *QueueItem) GetCleanupFunction() *CleanupFunctionOp {
	if x, ok := m.GetItem().(*QueueItem_CleanupFunction); ok {
		return x.CleanupFunction
	}
	return nil
}

// XXX_OneofWrappers is for the internal use of the proto package.
func (*QueueItem) XXX_OneofWrappers() []interface{} {
	return []interface{}{
		(*QueueItem_HandleToDecref)(nil),
		(*QueueItem_Operation)(nil),
		(*QueueItem_SendTensor)(nil),
		(*QueueItem_RegisterFunction)(nil),
		(*QueueItem_CleanupFunction)(nil),
	}
}

type QueueResponse struct {
	Shape                []*framework.TensorShapeProto `protobuf:"bytes,1,rep,name=shape,proto3" json:"shape,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                      `json:"-"`
	XXX_unrecognized     []byte                        `json:"-"`
	XXX_sizecache        int32                         `json:"-"`
}

func (m *QueueResponse) Reset()         { *m = QueueResponse{} }
func (m *QueueResponse) String() string { return proto.CompactTextString(m) }
func (*QueueResponse) ProtoMessage()    {}
func (*QueueResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_7c18508aed02748c, []int{2}
}

func (m *QueueResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_QueueResponse.Unmarshal(m, b)
}
func (m *QueueResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_QueueResponse.Marshal(b, m, deterministic)
}
func (m *QueueResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_QueueResponse.Merge(m, src)
}
func (m *QueueResponse) XXX_Size() int {
	return xxx_messageInfo_QueueResponse.Size(m)
}
func (m *QueueResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_QueueResponse.DiscardUnknown(m)
}

var xxx_messageInfo_QueueResponse proto.InternalMessageInfo

func (m *QueueResponse) GetShape() []*framework.TensorShapeProto {
	if m != nil {
		return m.Shape
	}
	return nil
}

type CreateContextRequest struct {
	// Identifies the full cluster, and this particular worker's position within.
	ServerDef *ServerDef `protobuf:"bytes,1,opt,name=server_def,json=serverDef,proto3" json:"server_def,omitempty"`
	// Whether the ops on the worker should be executed synchronously or
	// asynchronously. By default, ops are executed synchronously.
	Async bool `protobuf:"varint,2,opt,name=async,proto3" json:"async,omitempty"`
	// Number of seconds to keep the context alive. If more than keep_alive_secs
	// has passed since a particular context has been communicated with, it will
	// be garbage collected.
	KeepAliveSecs int64 `protobuf:"varint,3,opt,name=keep_alive_secs,json=keepAliveSecs,proto3" json:"keep_alive_secs,omitempty"`
	// This is the version for all the ops that will be enqueued by the client.
	VersionDef *framework.VersionDef `protobuf:"bytes,4,opt,name=version_def,json=versionDef,proto3" json:"version_def,omitempty"`
	// Device attributes in the cluster
	ClusterDeviceAttributes []*framework.DeviceAttributes `protobuf:"bytes,6,rep,name=cluster_device_attributes,json=clusterDeviceAttributes,proto3" json:"cluster_device_attributes,omitempty"`
	// The ID of the created context. This is usually a randomly generated number,
	// that will be used to identify the context in future requests to the
	// service. Contexts are not persisted through server restarts.
	// This ID will be used for all future communications as well. It is essential
	// that both ends use this ID for selecting a rendezvous to get everything to
	// match.
	ContextId uint64 `protobuf:"fixed64,7,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	// The view ID of the context.
	ContextViewId uint64 `protobuf:"fixed64,8,opt,name=context_view_id,json=contextViewId,proto3" json:"context_view_id,omitempty"`
	// For a multi device function, if false, eagerly copy all remote inputs to
	// the default function device; if true, lazily copy remote inputs to their
	// target devices after function instantiation to avoid redundant copies.
	LazyCopyRemoteFunctionInputs bool     `protobuf:"varint,9,opt,name=lazy_copy_remote_function_inputs,json=lazyCopyRemoteFunctionInputs,proto3" json:"lazy_copy_remote_function_inputs,omitempty"`
	XXX_NoUnkeyedLiteral         struct{} `json:"-"`
	XXX_unrecognized             []byte   `json:"-"`
	XXX_sizecache                int32    `json:"-"`
}

func (m *CreateContextRequest) Reset()         { *m = CreateContextRequest{} }
func (m *CreateContextRequest) String() string { return proto.CompactTextString(m) }
func (*CreateContextRequest) ProtoMessage()    {}
func (*CreateContextRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_7c18508aed02748c, []int{3}
}

func (m *CreateContextRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_CreateContextRequest.Unmarshal(m, b)
}
func (m *CreateContextRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_CreateContextRequest.Marshal(b, m, deterministic)
}
func (m *CreateContextRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CreateContextRequest.Merge(m, src)
}
func (m *CreateContextRequest) XXX_Size() int {
	return xxx_messageInfo_CreateContextRequest.Size(m)
}
func (m *CreateContextRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_CreateContextRequest.DiscardUnknown(m)
}

var xxx_messageInfo_CreateContextRequest proto.InternalMessageInfo

func (m *CreateContextRequest) GetServerDef() *ServerDef {
	if m != nil {
		return m.ServerDef
	}
	return nil
}

func (m *CreateContextRequest) GetAsync() bool {
	if m != nil {
		return m.Async
	}
	return false
}

func (m *CreateContextRequest) GetKeepAliveSecs() int64 {
	if m != nil {
		return m.KeepAliveSecs
	}
	return 0
}

func (m *CreateContextRequest) GetVersionDef() *framework.VersionDef {
	if m != nil {
		return m.VersionDef
	}
	return nil
}

func (m *CreateContextRequest) GetClusterDeviceAttributes() []*framework.DeviceAttributes {
	if m != nil {
		return m.ClusterDeviceAttributes
	}
	return nil
}

func (m *CreateContextRequest) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

func (m *CreateContextRequest) GetContextViewId() uint64 {
	if m != nil {
		return m.ContextViewId
	}
	return 0
}

func (m *CreateContextRequest) GetLazyCopyRemoteFunctionInputs() bool {
	if m != nil {
		return m.LazyCopyRemoteFunctionInputs
	}
	return false
}

type CreateContextResponse struct {
	// List of devices that are locally accessible to the worker.
	DeviceAttributes     []*framework.DeviceAttributes `protobuf:"bytes,2,rep,name=device_attributes,json=deviceAttributes,proto3" json:"device_attributes,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                      `json:"-"`
	XXX_unrecognized     []byte                        `json:"-"`
	XXX_sizecache        int32                         `json:"-"`
}

func (m *CreateContextResponse) Reset()         { *m = CreateContextResponse{} }
func (m *CreateContextResponse) String() string { return proto.CompactTextString(m) }
func (*CreateContextResponse) ProtoMessage()    {}
func (*CreateContextResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_7c18508aed02748c, []int{4}
}

func (m *CreateContextResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_CreateContextResponse.Unmarshal(m, b)
}
func (m *CreateContextResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_CreateContextResponse.Marshal(b, m, deterministic)
}
func (m *CreateContextResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CreateContextResponse.Merge(m, src)
}
func (m *CreateContextResponse) XXX_Size() int {
	return xxx_messageInfo_CreateContextResponse.Size(m)
}
func (m *CreateContextResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_CreateContextResponse.DiscardUnknown(m)
}

var xxx_messageInfo_CreateContextResponse proto.InternalMessageInfo

func (m *CreateContextResponse) GetDeviceAttributes() []*framework.DeviceAttributes {
	if m != nil {
		return m.DeviceAttributes
	}
	return nil
}

type UpdateContextRequest struct {
	// Identifies the full cluster, and this particular worker's position within.
	ServerDef *ServerDef `protobuf:"bytes,1,opt,name=server_def,json=serverDef,proto3" json:"server_def,omitempty"`
	// Device attributes in the cluster
	ClusterDeviceAttributes []*framework.DeviceAttributes `protobuf:"bytes,2,rep,name=cluster_device_attributes,json=clusterDeviceAttributes,proto3" json:"cluster_device_attributes,omitempty"`
	// The ID of the context to be updated. A context with the specified ID must
	// already exist on the recepient server of this request.
	ContextId uint64 `protobuf:"fixed64,3,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	// The view ID of the context, which should be contiguously incremented when
	// updating the same context.
	ContextViewId        uint64   `protobuf:"fixed64,4,opt,name=context_view_id,json=contextViewId,proto3" json:"context_view_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *UpdateContextRequest) Reset()         { *m = UpdateContextRequest{} }
func (m *UpdateContextRequest) String() string { return proto.CompactTextString(m) }
func (*UpdateContextRequest) ProtoMessage()    {}
func (*UpdateContextRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_7c18508aed02748c, []int{5}
}

func (m *UpdateContextRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_UpdateContextRequest.Unmarshal(m, b)
}
func (m *UpdateContextRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_UpdateContextRequest.Marshal(b, m, deterministic)
}
func (m *UpdateContextRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_UpdateContextRequest.Merge(m, src)
}
func (m *UpdateContextRequest) XXX_Size() int {
	return xxx_messageInfo_UpdateContextRequest.Size(m)
}
func (m *UpdateContextRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_UpdateContextRequest.DiscardUnknown(m)
}

var xxx_messageInfo_UpdateContextRequest proto.InternalMessageInfo

func (m *UpdateContextRequest) GetServerDef() *ServerDef {
	if m != nil {
		return m.ServerDef
	}
	return nil
}

func (m *UpdateContextRequest) GetClusterDeviceAttributes() []*framework.DeviceAttributes {
	if m != nil {
		return m.ClusterDeviceAttributes
	}
	return nil
}

func (m *UpdateContextRequest) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

func (m *UpdateContextRequest) GetContextViewId() uint64 {
	if m != nil {
		return m.ContextViewId
	}
	return 0
}

type UpdateContextResponse struct {
	// List of devices that are locally accessible to the worker.
	DeviceAttributes     []*framework.DeviceAttributes `protobuf:"bytes,1,rep,name=device_attributes,json=deviceAttributes,proto3" json:"device_attributes,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                      `json:"-"`
	XXX_unrecognized     []byte                        `json:"-"`
	XXX_sizecache        int32                         `json:"-"`
}

func (m *UpdateContextResponse) Reset()         { *m = UpdateContextResponse{} }
func (m *UpdateContextResponse) String() string { return proto.CompactTextString(m) }
func (*UpdateContextResponse) ProtoMessage()    {}
func (*UpdateContextResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_7c18508aed02748c, []int{6}
}

func (m *UpdateContextResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_UpdateContextResponse.Unmarshal(m, b)
}
func (m *UpdateContextResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_UpdateContextResponse.Marshal(b, m, deterministic)
}
func (m *UpdateContextResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_UpdateContextResponse.Merge(m, src)
}
func (m *UpdateContextResponse) XXX_Size() int {
	return xxx_messageInfo_UpdateContextResponse.Size(m)
}
func (m *UpdateContextResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_UpdateContextResponse.DiscardUnknown(m)
}

var xxx_messageInfo_UpdateContextResponse proto.InternalMessageInfo

func (m *UpdateContextResponse) GetDeviceAttributes() []*framework.DeviceAttributes {
	if m != nil {
		return m.DeviceAttributes
	}
	return nil
}

type EnqueueRequest struct {
	ContextId            uint64       `protobuf:"fixed64,1,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	Queue                []*QueueItem `protobuf:"bytes,3,rep,name=queue,proto3" json:"queue,omitempty"`
	XXX_NoUnkeyedLiteral struct{}     `json:"-"`
	XXX_unrecognized     []byte       `json:"-"`
	XXX_sizecache        int32        `json:"-"`
}

func (m *EnqueueRequest) Reset()         { *m = EnqueueRequest{} }
func (m *EnqueueRequest) String() string { return proto.CompactTextString(m) }
func (*EnqueueRequest) ProtoMessage()    {}
func (*EnqueueRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_7c18508aed02748c, []int{7}
}

func (m *EnqueueRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_EnqueueRequest.Unmarshal(m, b)
}
func (m *EnqueueRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_EnqueueRequest.Marshal(b, m, deterministic)
}
func (m *EnqueueRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_EnqueueRequest.Merge(m, src)
}
func (m *EnqueueRequest) XXX_Size() int {
	return xxx_messageInfo_EnqueueRequest.Size(m)
}
func (m *EnqueueRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_EnqueueRequest.DiscardUnknown(m)
}

var xxx_messageInfo_EnqueueRequest proto.InternalMessageInfo

func (m *EnqueueRequest) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

func (m *EnqueueRequest) GetQueue() []*QueueItem {
	if m != nil {
		return m.Queue
	}
	return nil
}

type EnqueueResponse struct {
	// A single operation response for every item in the request.
	QueueResponse        []*QueueResponse `protobuf:"bytes,1,rep,name=queue_response,json=queueResponse,proto3" json:"queue_response,omitempty"`
	XXX_NoUnkeyedLiteral struct{}         `json:"-"`
	XXX_unrecognized     []byte           `json:"-"`
	XXX_sizecache        int32            `json:"-"`
}

func (m *EnqueueResponse) Reset()         { *m = EnqueueResponse{} }
func (m *EnqueueResponse) String() string { return proto.CompactTextString(m) }
func (*EnqueueResponse) ProtoMessage()    {}
func (*EnqueueResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_7c18508aed02748c, []int{8}
}

func (m *EnqueueResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_EnqueueResponse.Unmarshal(m, b)
}
func (m *EnqueueResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_EnqueueResponse.Marshal(b, m, deterministic)
}
func (m *EnqueueResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_EnqueueResponse.Merge(m, src)
}
func (m *EnqueueResponse) XXX_Size() int {
	return xxx_messageInfo_EnqueueResponse.Size(m)
}
func (m *EnqueueResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_EnqueueResponse.DiscardUnknown(m)
}

var xxx_messageInfo_EnqueueResponse proto.InternalMessageInfo

func (m *EnqueueResponse) GetQueueResponse() []*QueueResponse {
	if m != nil {
		return m.QueueResponse
	}
	return nil
}

type WaitQueueDoneRequest struct {
	ContextId uint64 `protobuf:"fixed64,1,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	// Ids to wait on. If empty, wait on everything currently pending.
	OpId                 []int64  `protobuf:"varint,2,rep,packed,name=op_id,json=opId,proto3" json:"op_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *WaitQueueDoneRequest) Reset()         { *m = WaitQueueDoneRequest{} }
func (m *WaitQueueDoneRequest) String() string { return proto.CompactTextString(m) }
func (*WaitQueueDoneRequest) ProtoMessage()    {}
func (*WaitQueueDoneRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_7c18508aed02748c, []int{9}
}

func (m *WaitQueueDoneRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_WaitQueueDoneRequest.Unmarshal(m, b)
}
func (m *WaitQueueDoneRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_WaitQueueDoneRequest.Marshal(b, m, deterministic)
}
func (m *WaitQueueDoneRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_WaitQueueDoneRequest.Merge(m, src)
}
func (m *WaitQueueDoneRequest) XXX_Size() int {
	return xxx_messageInfo_WaitQueueDoneRequest.Size(m)
}
func (m *WaitQueueDoneRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_WaitQueueDoneRequest.DiscardUnknown(m)
}

var xxx_messageInfo_WaitQueueDoneRequest proto.InternalMessageInfo

func (m *WaitQueueDoneRequest) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

func (m *WaitQueueDoneRequest) GetOpId() []int64 {
	if m != nil {
		return m.OpId
	}
	return nil
}

type WaitQueueDoneResponse struct {
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *WaitQueueDoneResponse) Reset()         { *m = WaitQueueDoneResponse{} }
func (m *WaitQueueDoneResponse) String() string { return proto.CompactTextString(m) }
func (*WaitQueueDoneResponse) ProtoMessage()    {}
func (*WaitQueueDoneResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_7c18508aed02748c, []int{10}
}

func (m *WaitQueueDoneResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_WaitQueueDoneResponse.Unmarshal(m, b)
}
func (m *WaitQueueDoneResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_WaitQueueDoneResponse.Marshal(b, m, deterministic)
}
func (m *WaitQueueDoneResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_WaitQueueDoneResponse.Merge(m, src)
}
func (m *WaitQueueDoneResponse) XXX_Size() int {
	return xxx_messageInfo_WaitQueueDoneResponse.Size(m)
}
func (m *WaitQueueDoneResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_WaitQueueDoneResponse.DiscardUnknown(m)
}

var xxx_messageInfo_WaitQueueDoneResponse proto.InternalMessageInfo

type KeepAliveRequest struct {
	ContextId            uint64   `protobuf:"fixed64,1,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *KeepAliveRequest) Reset()         { *m = KeepAliveRequest{} }
func (m *KeepAliveRequest) String() string { return proto.CompactTextString(m) }
func (*KeepAliveRequest) ProtoMessage()    {}
func (*KeepAliveRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_7c18508aed02748c, []int{11}
}

func (m *KeepAliveRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_KeepAliveRequest.Unmarshal(m, b)
}
func (m *KeepAliveRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_KeepAliveRequest.Marshal(b, m, deterministic)
}
func (m *KeepAliveRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_KeepAliveRequest.Merge(m, src)
}
func (m *KeepAliveRequest) XXX_Size() int {
	return xxx_messageInfo_KeepAliveRequest.Size(m)
}
func (m *KeepAliveRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_KeepAliveRequest.DiscardUnknown(m)
}

var xxx_messageInfo_KeepAliveRequest proto.InternalMessageInfo

func (m *KeepAliveRequest) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

type KeepAliveResponse struct {
	// If the requested context_id is on the remote host, set the context view ID.
	ContextViewId        uint64   `protobuf:"fixed64,1,opt,name=context_view_id,json=contextViewId,proto3" json:"context_view_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *KeepAliveResponse) Reset()         { *m = KeepAliveResponse{} }
func (m *KeepAliveResponse) String() string { return proto.CompactTextString(m) }
func (*KeepAliveResponse) ProtoMessage()    {}
func (*KeepAliveResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_7c18508aed02748c, []int{12}
}

func (m *KeepAliveResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_KeepAliveResponse.Unmarshal(m, b)
}
func (m *KeepAliveResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_KeepAliveResponse.Marshal(b, m, deterministic)
}
func (m *KeepAliveResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_KeepAliveResponse.Merge(m, src)
}
func (m *KeepAliveResponse) XXX_Size() int {
	return xxx_messageInfo_KeepAliveResponse.Size(m)
}
func (m *KeepAliveResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_KeepAliveResponse.DiscardUnknown(m)
}

var xxx_messageInfo_KeepAliveResponse proto.InternalMessageInfo

func (m *KeepAliveResponse) GetContextViewId() uint64 {
	if m != nil {
		return m.ContextViewId
	}
	return 0
}

type CloseContextRequest struct {
	ContextId            uint64   `protobuf:"fixed64,1,opt,name=context_id,json=contextId,proto3" json:"context_id,omitempty"`
	ContextViewId        uint64   `protobuf:"fixed64,2,opt,name=context_view_id,json=contextViewId,proto3" json:"context_view_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *CloseContextRequest) Reset()         { *m = CloseContextRequest{} }
func (m *CloseContextRequest) String() string { return proto.CompactTextString(m) }
func (*CloseContextRequest) ProtoMessage()    {}
func (*CloseContextRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_7c18508aed02748c, []int{13}
}

func (m *CloseContextRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_CloseContextRequest.Unmarshal(m, b)
}
func (m *CloseContextRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_CloseContextRequest.Marshal(b, m, deterministic)
}
func (m *CloseContextRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CloseContextRequest.Merge(m, src)
}
func (m *CloseContextRequest) XXX_Size() int {
	return xxx_messageInfo_CloseContextRequest.Size(m)
}
func (m *CloseContextRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_CloseContextRequest.DiscardUnknown(m)
}

var xxx_messageInfo_CloseContextRequest proto.InternalMessageInfo

func (m *CloseContextRequest) GetContextId() uint64 {
	if m != nil {
		return m.ContextId
	}
	return 0
}

func (m *CloseContextRequest) GetContextViewId() uint64 {
	if m != nil {
		return m.ContextViewId
	}
	return 0
}

type CloseContextResponse struct {
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *CloseContextResponse) Reset()         { *m = CloseContextResponse{} }
func (m *CloseContextResponse) String() string { return proto.CompactTextString(m) }
func (*CloseContextResponse) ProtoMessage()    {}
func (*CloseContextResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_7c18508aed02748c, []int{14}
}

func (m *CloseContextResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_CloseContextResponse.Unmarshal(m, b)
}
func (m *CloseContextResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_CloseContextResponse.Marshal(b, m, deterministic)
}
func (m *CloseContextResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CloseContextResponse.Merge(m, src)
}
func (m *CloseContextResponse) XXX_Size() int {
	return xxx_messageInfo_CloseContextResponse.Size(m)
}
func (m *CloseContextResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_CloseContextResponse.DiscardUnknown(m)
}

var xxx_messageInfo_CloseContextResponse proto.InternalMessageInfo

type RegisterFunctionOp struct {
	FunctionDef *framework.FunctionDef `protobuf:"bytes,1,opt,name=function_def,json=functionDef,proto3" json:"function_def,omitempty"`
	// If true, it means that function_def is produced by graph partition during
	// multi-device function instantiation.
	IsComponentFunction bool `protobuf:"varint,2,opt,name=is_component_function,json=isComponentFunction,proto3" json:"is_component_function,omitempty"`
	// All necessary FunctionDefs and GradientDefs to expand `function_def`.
	// When is_component_function is true, `function_def` could be a nested
	// function, since some nodes in its parent's function body could be
	// replaced with a new function by the graph optimization passes. No need to
	// add FunctionDefs here to the function cache in EagerContext since they
	// won't be executed as KernelAndDevices.
	Library              *framework.FunctionDefLibrary `protobuf:"bytes,3,opt,name=library,proto3" json:"library,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                      `json:"-"`
	XXX_unrecognized     []byte                        `json:"-"`
	XXX_sizecache        int32                         `json:"-"`
}

func (m *RegisterFunctionOp) Reset()         { *m = RegisterFunctionOp{} }
func (m *RegisterFunctionOp) String() string { return proto.CompactTextString(m) }
func (*RegisterFunctionOp) ProtoMessage()    {}
func (*RegisterFunctionOp) Descriptor() ([]byte, []int) {
	return fileDescriptor_7c18508aed02748c, []int{15}
}

func (m *RegisterFunctionOp) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_RegisterFunctionOp.Unmarshal(m, b)
}
func (m *RegisterFunctionOp) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_RegisterFunctionOp.Marshal(b, m, deterministic)
}
func (m *RegisterFunctionOp) XXX_Merge(src proto.Message) {
	xxx_messageInfo_RegisterFunctionOp.Merge(m, src)
}
func (m *RegisterFunctionOp) XXX_Size() int {
	return xxx_messageInfo_RegisterFunctionOp.Size(m)
}
func (m *RegisterFunctionOp) XXX_DiscardUnknown() {
	xxx_messageInfo_RegisterFunctionOp.DiscardUnknown(m)
}

var xxx_messageInfo_RegisterFunctionOp proto.InternalMessageInfo

func (m *RegisterFunctionOp) GetFunctionDef() *framework.FunctionDef {
	if m != nil {
		return m.FunctionDef
	}
	return nil
}

func (m *RegisterFunctionOp) GetIsComponentFunction() bool {
	if m != nil {
		return m.IsComponentFunction
	}
	return false
}

func (m *RegisterFunctionOp) GetLibrary() *framework.FunctionDefLibrary {
	if m != nil {
		return m.Library
	}
	return nil
}

// Cleanup the step state of a multi-device function (e.g. tensors buffered by
// a `Send` op but not picked up by its corresponding `Recv` op).
type CleanupFunctionOp struct {
	StepId               int64    `protobuf:"varint,1,opt,name=step_id,json=stepId,proto3" json:"step_id,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *CleanupFunctionOp) Reset()         { *m = CleanupFunctionOp{} }
func (m *CleanupFunctionOp) String() string { return proto.CompactTextString(m) }
func (*CleanupFunctionOp) ProtoMessage()    {}
func (*CleanupFunctionOp) Descriptor() ([]byte, []int) {
	return fileDescriptor_7c18508aed02748c, []int{16}
}

func (m *CleanupFunctionOp) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_CleanupFunctionOp.Unmarshal(m, b)
}
func (m *CleanupFunctionOp) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_CleanupFunctionOp.Marshal(b, m, deterministic)
}
func (m *CleanupFunctionOp) XXX_Merge(src proto.Message) {
	xxx_messageInfo_CleanupFunctionOp.Merge(m, src)
}
func (m *CleanupFunctionOp) XXX_Size() int {
	return xxx_messageInfo_CleanupFunctionOp.Size(m)
}
func (m *CleanupFunctionOp) XXX_DiscardUnknown() {
	xxx_messageInfo_CleanupFunctionOp.DiscardUnknown(m)
}

var xxx_messageInfo_CleanupFunctionOp proto.InternalMessageInfo

func (m *CleanupFunctionOp) GetStepId() int64 {
	if m != nil {
		return m.StepId
	}
	return 0
}

type SendTensorOp struct {
	// All remote tensors are identified by <Op ID, Output num>. To mimic this
	// situation when directly sending tensors, we include an "artificial" op ID
	// (which would have corresponded to the _Recv op when not using SendTensor).
	OpId int64 `protobuf:"varint,1,opt,name=op_id,json=opId,proto3" json:"op_id,omitempty"`
	// The index within the repeated field is the output number that will help
	// uniquely identify (along with the above op_id) the particular tensor.
	Tensors []*framework.TensorProto `protobuf:"bytes,2,rep,name=tensors,proto3" json:"tensors,omitempty"`
	// The device on which the tensors should be resident.
	DeviceName           string   `protobuf:"bytes,3,opt,name=device_name,json=deviceName,proto3" json:"device_name,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *SendTensorOp) Reset()         { *m = SendTensorOp{} }
func (m *SendTensorOp) String() string { return proto.CompactTextString(m) }
func (*SendTensorOp) ProtoMessage()    {}
func (*SendTensorOp) Descriptor() ([]byte, []int) {
	return fileDescriptor_7c18508aed02748c, []int{17}
}

func (m *SendTensorOp) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_SendTensorOp.Unmarshal(m, b)
}
func (m *SendTensorOp) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_SendTensorOp.Marshal(b, m, deterministic)
}
func (m *SendTensorOp) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SendTensorOp.Merge(m, src)
}
func (m *SendTensorOp) XXX_Size() int {
	return xxx_messageInfo_SendTensorOp.Size(m)
}
func (m *SendTensorOp) XXX_DiscardUnknown() {
	xxx_messageInfo_SendTensorOp.DiscardUnknown(m)
}

var xxx_messageInfo_SendTensorOp proto.InternalMessageInfo

func (m *SendTensorOp) GetOpId() int64 {
	if m != nil {
		return m.OpId
	}
	return 0
}

func (m *SendTensorOp) GetTensors() []*framework.TensorProto {
	if m != nil {
		return m.Tensors
	}
	return nil
}

func (m *SendTensorOp) GetDeviceName() string {
	if m != nil {
		return m.DeviceName
	}
	return ""
}

func init() {
	proto.RegisterType((*Operation)(nil), "tensorflow.eager.Operation")
	proto.RegisterMapType((map[string]*framework.AttrValue)(nil), "tensorflow.eager.Operation.AttrsEntry")
	proto.RegisterType((*QueueItem)(nil), "tensorflow.eager.QueueItem")
	proto.RegisterType((*QueueResponse)(nil), "tensorflow.eager.QueueResponse")
	proto.RegisterType((*CreateContextRequest)(nil), "tensorflow.eager.CreateContextRequest")
	proto.RegisterType((*CreateContextResponse)(nil), "tensorflow.eager.CreateContextResponse")
	proto.RegisterType((*UpdateContextRequest)(nil), "tensorflow.eager.UpdateContextRequest")
	proto.RegisterType((*UpdateContextResponse)(nil), "tensorflow.eager.UpdateContextResponse")
	proto.RegisterType((*EnqueueRequest)(nil), "tensorflow.eager.EnqueueRequest")
	proto.RegisterType((*EnqueueResponse)(nil), "tensorflow.eager.EnqueueResponse")
	proto.RegisterType((*WaitQueueDoneRequest)(nil), "tensorflow.eager.WaitQueueDoneRequest")
	proto.RegisterType((*WaitQueueDoneResponse)(nil), "tensorflow.eager.WaitQueueDoneResponse")
	proto.RegisterType((*KeepAliveRequest)(nil), "tensorflow.eager.KeepAliveRequest")
	proto.RegisterType((*KeepAliveResponse)(nil), "tensorflow.eager.KeepAliveResponse")
	proto.RegisterType((*CloseContextRequest)(nil), "tensorflow.eager.CloseContextRequest")
	proto.RegisterType((*CloseContextResponse)(nil), "tensorflow.eager.CloseContextResponse")
	proto.RegisterType((*RegisterFunctionOp)(nil), "tensorflow.eager.RegisterFunctionOp")
	proto.RegisterType((*CleanupFunctionOp)(nil), "tensorflow.eager.CleanupFunctionOp")
	proto.RegisterType((*SendTensorOp)(nil), "tensorflow.eager.SendTensorOp")
}

func init() {
	proto.RegisterFile("github.com/smoug25/tensorflow_serving_helper/tensorflow/core/protobuf/eager_service.proto", fileDescriptor_7c18508aed02748c)
}

var fileDescriptor_7c18508aed02748c = []byte{
	// 1288 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xac, 0x57, 0xeb, 0x72, 0xdb, 0x44,
	0x14, 0xae, 0x2c, 0xdb, 0x89, 0x4f, 0x2e, 0x75, 0xb6, 0x49, 0x63, 0x4c, 0xa1, 0x46, 0x2d, 0x25,
	0x33, 0x30, 0x09, 0x0d, 0x30, 0x74, 0xda, 0xfe, 0x49, 0x9d, 0x94, 0xb8, 0x30, 0x4d, 0x59, 0xf7,
	0x42, 0x81, 0xa2, 0xca, 0xd2, 0x71, 0xa2, 0xa9, 0xad, 0x55, 0xb5, 0x6b, 0x07, 0xf3, 0x0c, 0xfc,
	0xe6, 0x3d, 0xe0, 0x01, 0x78, 0x23, 0xde, 0x81, 0xd9, 0x8b, 0x7c, 0x55, 0xd2, 0x0c, 0xf8, 0x9f,
	0x7c, 0xf6, 0x3b, 0xdf, 0xb9, 0x9f, 0x5d, 0xc3, 0xcb, 0xe3, 0x50, 0x9c, 0xf4, 0x5a, 0xdb, 0x3e,
	0xeb, 0xee, 0xf0, 0x2e, 0xeb, 0x1d, 0xef, 0x7e, 0xb5, 0x23, 0x30, 0xe2, 0x2c, 0x69, 0x77, 0xd8,
	0xa9, 0xcb, 0x31, 0xe9, 0x87, 0xd1, 0xb1, 0x7b, 0x82, 0x9d, 0x18, 0x93, 0xb1, 0x93, 0x1d, 0x9f,
	0x25, 0xb8, 0x13, 0x27, 0x4c, 0xb0, 0x56, 0xaf, 0xbd, 0x83, 0xde, 0x31, 0x26, 0x1a, 0xed, 0xe3,
	0xb6, 0x12, 0x93, 0xf2, 0x08, 0xbd, 0xad, 0xce, 0xab, 0x2f, 0xfe, 0x97, 0xb1, 0x76, 0xe2, 0x75,
	0xf1, 0x94, 0x25, 0x6f, 0x76, 0x3c, 0x21, 0x12, 0xb7, 0xef, 0x75, 0x7a, 0xc6, 0x54, 0xf5, 0x97,
	0x39, 0x11, 0x07, 0x28, 0xfd, 0x77, 0x25, 0x7f, 0xd8, 0xea, 0x09, 0xe4, 0x86, 0xff, 0xd9, 0x9c,
	0xf8, 0xdb, 0xbd, 0xc8, 0x17, 0x21, 0x8b, 0x0c, 0x6d, 0x73, 0x4e, 0xb4, 0xfa, 0xc4, 0x90, 0xbe,
	0x9c, 0x2b, 0xa9, 0xcb, 0x4f, 0xbc, 0x18, 0xe7, 0x9c, 0x86, 0x3e, 0x26, 0x3c, 0x64, 0x51, 0x9a,
	0xdd, 0xd7, 0xf3, 0xe9, 0xc1, 0x04, 0xbb, 0x4c, 0xa0, 0x6b, 0xfc, 0x3e, 0xf1, 0xa2, 0xa0, 0x93,
	0x3a, 0xfe, 0x6a, 0x3e, 0x16, 0xa6, 0x54, 0xd0, 0xa4, 0xdc, 0xf9, 0xd3, 0x86, 0xd2, 0x51, 0x8c,
	0x89, 0x27, 0x6b, 0x4b, 0x56, 0x21, 0x17, 0x06, 0x15, 0xab, 0x66, 0x6d, 0xd9, 0x34, 0x17, 0x06,
	0x84, 0x40, 0x3e, 0xf2, 0xba, 0x58, 0xc9, 0xd5, 0xac, 0xad, 0x12, 0x55, 0xdf, 0xe4, 0x3e, 0x14,
	0xc3, 0x28, 0xee, 0x09, 0x5e, 0xb1, 0x6b, 0xf6, 0xd6, 0xd2, 0xee, 0xcd, 0xed, 0xe9, 0x61, 0xd9,
	0xa6, 0x2a, 0x9c, 0xa7, 0x4a, 0x7c, 0xa8, 0x82, 0xa1, 0x46, 0x87, 0xdc, 0x84, 0x55, 0x9f, 0x45,
	0x22, 0x61, 0x1d, 0x97, 0xc5, 0x6e, 0x18, 0xf0, 0x4a, 0xbe, 0x66, 0x6f, 0xd9, 0x74, 0xd9, 0x48,
	0x8f, 0xe2, 0x46, 0xc0, 0xc9, 0x7d, 0x28, 0xc8, 0x46, 0xe6, 0x95, 0x82, 0x32, 0x71, 0x6b, 0xd6,
	0xc4, 0xd0, 0xe7, 0xed, 0x3d, 0x09, 0x3c, 0x88, 0x44, 0x32, 0xa0, 0x5a, 0x89, 0x5c, 0x85, 0xa2,
	0x9e, 0x86, 0x4a, 0x51, 0xf9, 0x6d, 0x7e, 0x91, 0x5d, 0xd8, 0x08, 0xb9, 0xeb, 0xb3, 0x6e, 0xcc,
	0x22, 0x8c, 0x84, 0x9b, 0xb6, 0x74, 0x65, 0xa1, 0x66, 0x6d, 0x2d, 0xd2, 0x2b, 0x21, 0xaf, 0xa7,
	0x67, 0x0f, 0xcd, 0x11, 0xa9, 0xc1, 0xb2, 0x84, 0xb9, 0x5c, 0xa0, 0x74, 0xb7, 0xb2, 0xa8, 0x72,
	0x03, 0x52, 0xd6, 0x14, 0x18, 0x37, 0x02, 0x72, 0x1d, 0x96, 0x42, 0x3e, 0xe2, 0x2a, 0x29, 0x2e,
	0x08, 0x79, 0x4a, 0x51, 0x3d, 0x02, 0x18, 0xf9, 0x48, 0xca, 0x60, 0xbf, 0xc1, 0x81, 0xca, 0x71,
	0x89, 0xca, 0x4f, 0xf2, 0x29, 0x14, 0xd4, 0x42, 0x50, 0x59, 0x5e, 0xda, 0xdd, 0x18, 0x0f, 0x56,
	0x2a, 0x3e, 0x97, 0x87, 0x54, 0x63, 0xee, 0xe6, 0xee, 0x58, 0xce, 0xef, 0x36, 0x94, 0xbe, 0xef,
	0x61, 0x0f, 0x1b, 0x02, 0xbb, 0xe4, 0x09, 0x94, 0x75, 0xc3, 0xb8, 0x82, 0xb9, 0x01, 0xfa, 0x09,
	0xb6, 0x15, 0xfb, 0x05, 0x2b, 0x73, 0x78, 0x89, 0xae, 0x6a, 0xfd, 0xa7, 0x6c, 0x5f, 0x69, 0x93,
	0x7b, 0x50, 0x62, 0x69, 0x7a, 0x8d, 0x53, 0xef, 0x9f, 0x53, 0x81, 0xc3, 0x4b, 0x74, 0x84, 0x27,
	0x7b, 0xb0, 0xc4, 0x31, 0x0a, 0x4c, 0x2f, 0x57, 0x6c, 0xa5, 0xfe, 0xe1, 0xac, 0x7a, 0x13, 0xa3,
	0x40, 0xfb, 0x71, 0x14, 0x1f, 0x5e, 0xa2, 0xc0, 0x87, 0xbf, 0x49, 0x13, 0xd6, 0x12, 0x3c, 0x0e,
	0xb9, 0xc0, 0x64, 0x94, 0xd7, 0xfc, 0xd9, 0x21, 0x69, 0x68, 0x9a, 0x6f, 0x45, 0x57, 0x4e, 0xa6,
	0xa4, 0x32, 0x4d, 0x7e, 0x07, 0xbd, 0xa8, 0x17, 0x8f, 0x38, 0x0b, 0x8a, 0xf3, 0xc6, 0x2c, 0x67,
	0x5d, 0x23, 0x27, 0x28, 0x2f, 0xfb, 0x93, 0xc2, 0x07, 0x45, 0xc8, 0x87, 0x02, 0xbb, 0x4e, 0x1d,
	0x56, 0x54, 0x35, 0x28, 0xf2, 0x98, 0x45, 0x5c, 0xf6, 0x59, 0x41, 0xad, 0x9e, 0x8a, 0xa5, 0xba,
	0xf7, 0xda, 0x38, 0xbf, 0x0e, 0xb1, 0x29, 0x8f, 0x9f, 0xc8, 0x01, 0xa4, 0x1a, 0xea, 0xfc, 0x65,
	0xc3, 0x7a, 0x3d, 0x41, 0x4f, 0x60, 0x9d, 0x45, 0x02, 0x7f, 0x15, 0x14, 0xdf, 0xf6, 0x90, 0x0b,
	0xf2, 0x25, 0x80, 0x1e, 0x58, 0x37, 0x18, 0x16, 0x76, 0xa2, 0x45, 0x9a, 0xea, 0x74, 0x1f, 0xdb,
	0xb4, 0xc4, 0xd3, 0x4f, 0xb2, 0x0e, 0x05, 0x8f, 0x0f, 0x22, 0x5f, 0x95, 0x6f, 0x91, 0xea, 0x1f,
	0xe4, 0x16, 0x5c, 0x7e, 0x83, 0x18, 0xbb, 0x5e, 0x27, 0xec, 0xa3, 0xcb, 0xd1, 0xe7, 0xaa, 0x3e,
	0x36, 0x5d, 0x91, 0xe2, 0x3d, 0x29, 0x6d, 0xa2, 0xcf, 0xc9, 0xd7, 0xb0, 0x64, 0xf6, 0x9c, 0x32,
	0xaa, 0x53, 0x7f, 0x75, 0xdc, 0xe8, 0x73, 0x7d, 0x2c, 0xad, 0x42, 0x7f, 0xf8, 0x4d, 0x7e, 0x80,
	0xf7, 0xfc, 0x4e, 0x4f, 0x15, 0x6e, 0xe6, 0x3e, 0xaa, 0x14, 0x67, 0xb3, 0xb1, 0xaf, 0x40, 0x7b,
	0x43, 0x0c, 0xdd, 0x34, 0xea, 0xd3, 0x07, 0xe4, 0x03, 0x00, 0x5f, 0x27, 0x46, 0x4e, 0xa1, 0x1c,
	0xd8, 0x22, 0x2d, 0x19, 0x49, 0x23, 0x90, 0x91, 0xa5, 0xc7, 0xfd, 0x10, 0x4f, 0xd3, 0x49, 0x2d,
	0xd2, 0x15, 0x23, 0x7e, 0x1e, 0xe2, 0x69, 0x23, 0x20, 0x0f, 0xa1, 0xd6, 0xf1, 0x7e, 0x1b, 0xb8,
	0x3e, 0x8b, 0x07, 0xae, 0xd9, 0xba, 0x69, 0x3b, 0xb8, 0x66, 0xad, 0xe9, 0x09, 0xbe, 0x26, 0x71,
	0x75, 0x16, 0x0f, 0xf4, 0xc8, 0xa4, 0x55, 0x6f, 0x28, 0xcc, 0xa3, 0xfc, 0x62, 0xa1, 0x5c, 0x74,
	0x4e, 0x60, 0x63, 0xaa, 0x66, 0xa6, 0x03, 0x1a, 0xb0, 0x36, 0x1b, 0x7f, 0xee, 0x02, 0xf1, 0x97,
	0x83, 0x29, 0xc9, 0xa3, 0xfc, 0xa2, 0x55, 0xce, 0x39, 0xff, 0x58, 0xb0, 0xfe, 0x2c, 0x0e, 0xe6,
	0xd5, 0x1e, 0xe7, 0xd6, 0x29, 0x37, 0xbf, 0x3a, 0xd9, 0x17, 0xa8, 0x53, 0x3e, 0xa3, 0x4e, 0x4e,
	0x0b, 0x36, 0xa6, 0xc2, 0x3d, 0x2f, 0xb3, 0xd6, 0x7f, 0xc9, 0xac, 0xd3, 0x82, 0xd5, 0x83, 0xe8,
	0xad, 0x9e, 0x5c, 0x9d, 0xcc, 0x49, 0xe7, 0xad, 0x69, 0xe7, 0x6f, 0x43, 0x41, 0xc1, 0xcd, 0xc5,
	0x97, 0xb1, 0x13, 0x87, 0x5b, 0x99, 0x6a, 0xa4, 0xf3, 0x12, 0x2e, 0x0f, 0x6d, 0x98, 0x08, 0x1e,
	0xc2, 0xaa, 0x12, 0xb8, 0x89, 0x91, 0x18, 0xf7, 0xaf, 0x9f, 0x41, 0x97, 0x2a, 0xd2, 0x95, 0x09,
	0x1e, 0xe7, 0x11, 0xac, 0xbf, 0xf0, 0x42, 0xa1, 0x30, 0xfb, 0x2c, 0xba, 0x68, 0x10, 0x57, 0xa0,
	0xa0, 0x2e, 0x5e, 0x55, 0x66, 0x9b, 0xe6, 0x59, 0xdc, 0x08, 0x9c, 0x4d, 0xd8, 0x98, 0xe2, 0x32,
	0x46, 0x6e, 0x43, 0xf9, 0xdb, 0x74, 0x35, 0x5c, 0xcc, 0x80, 0x73, 0x0f, 0xd6, 0xc6, 0x54, 0x4c,
	0xd0, 0x19, 0x75, 0xb7, 0xb2, 0xea, 0xfe, 0x33, 0x5c, 0xa9, 0x77, 0x18, 0x9f, 0xee, 0xf2, 0x77,
	0xc4, 0x94, 0xc1, 0x9e, 0xcb, 0x62, 0xbf, 0x0a, 0xeb, 0x93, 0xec, 0x26, 0xca, 0xbf, 0x2d, 0x20,
	0xb3, 0xd7, 0x08, 0xb9, 0xab, 0xef, 0x7e, 0x91, 0xee, 0x41, 0x3d, 0x5d, 0x9b, 0xe3, 0x75, 0x4a,
	0xd1, 0x72, 0xbe, 0x96, 0xda, 0xa3, 0x1f, 0x67, 0xbf, 0x35, 0x72, 0x67, 0xbf, 0x35, 0xee, 0xc0,
	0x42, 0x27, 0x6c, 0x25, 0x5e, 0x32, 0xc8, 0xba, 0x36, 0xc7, 0x4c, 0x7d, 0xa7, 0x51, 0x34, 0x85,
	0x3b, 0x9f, 0xc1, 0xda, 0xcc, 0x95, 0x45, 0x36, 0x61, 0x21, 0x7d, 0xb5, 0xe8, 0x17, 0x5d, 0x91,
	0xab, 0x17, 0x8b, 0x73, 0x0a, 0xcb, 0xe3, 0xb7, 0xef, 0xa8, 0x25, 0x34, 0x4c, 0xb5, 0x04, 0xb9,
	0x0d, 0x0b, 0xda, 0x78, 0xba, 0x10, 0x36, 0x67, 0xaf, 0x31, 0x7d, 0x83, 0xa5, 0x38, 0xf9, 0x12,
	0x32, 0xb3, 0xa9, 0x1e, 0x8d, 0xb6, 0x7a, 0xe2, 0x80, 0x16, 0x3d, 0xf6, 0xba, 0xb8, 0xfb, 0x47,
	0x01, 0x96, 0x0f, 0x64, 0x67, 0x37, 0xf5, 0xbf, 0x2d, 0xf2, 0x1a, 0x56, 0x26, 0x16, 0x28, 0xc9,
	0x78, 0xe9, 0x65, 0xdd, 0x8a, 0xd5, 0x4f, 0xde, 0x89, 0x33, 0x8d, 0xf7, 0x1a, 0x56, 0x26, 0x16,
	0x49, 0x96, 0x85, 0xac, 0xc5, 0x9a, 0x65, 0x21, 0x7b, 0x23, 0x3d, 0x86, 0x05, 0x33, 0xe2, 0xa4,
	0x36, 0xab, 0x33, 0xb9, 0x61, 0xaa, 0x1f, 0x9d, 0x83, 0x30, 0x7c, 0x3f, 0x41, 0xb9, 0x29, 0x12,
	0xf4, 0xba, 0x61, 0x74, 0x3c, 0x4f, 0xe2, 0x2d, 0xeb, 0x73, 0x4b, 0xa6, 0x63, 0x62, 0xd0, 0xb3,
	0xd2, 0x91, 0xb5, 0x55, 0xb2, 0xd2, 0x91, 0xb9, 0x31, 0xc8, 0x53, 0x28, 0x0d, 0xc7, 0x9f, 0x38,
	0xb3, 0x5a, 0xd3, 0xeb, 0xa4, 0x7a, 0xe3, 0x5c, 0x8c, 0x61, 0x7d, 0x05, 0xcb, 0xe3, 0x93, 0x4b,
	0x3e, 0xce, 0x7a, 0xb3, 0xcd, 0xec, 0x8d, 0xea, 0xad, 0x77, 0xc1, 0x34, 0xfd, 0x83, 0x6f, 0x7e,
	0x3c, 0x98, 0xcb, 0xdf, 0xac, 0x56, 0x51, 0x7d, 0x7d, 0xf1, 0x6f, 0x00, 0x00, 0x00, 0xff, 0xff,
	0x9b, 0xd8, 0xbf, 0xe2, 0x9c, 0x10, 0x00, 0x00,
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// EagerServiceClient is the client API for EagerService service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.
type EagerServiceClient interface {
	// This initializes the worker, informing it about the other workers in the
	// cluster and exchanging authentication tokens which will be used in all
	// other RPCs to detect whether the worker has restarted.
	CreateContext(ctx context.Context, in *CreateContextRequest, opts ...grpc.CallOption) (*CreateContextResponse, error)
	// This updates the eager context on an existing worker when updating the set
	// of servers in a distributed eager cluster.
	UpdateContext(ctx context.Context, in *UpdateContextRequest, opts ...grpc.CallOption) (*UpdateContextResponse, error)
	// This takes a list of Execute and DeleteTensorHandle operations and enqueues
	// (in async mode) or executes (in sync mode) them on the remote server.
	// All outputs of ops which were not explicitly deleted with
	// DeleteTensorHandle entries will be assumed to be alive and are usable by
	// future calls to Enqueue.
	Enqueue(ctx context.Context, in *EnqueueRequest, opts ...grpc.CallOption) (*EnqueueResponse, error)
	// A streaming version of Enqueue.
	// Current server implementation sends one response per received request.
	// The benefit for using a streaming version is that subsequent requests
	// can be sent without waiting for a response to the previous request. This
	// synchronization is required in the regular Enqueue call because gRPC does
	// not guarantee to preserve request order.
	StreamingEnqueue(ctx context.Context, opts ...grpc.CallOption) (EagerService_StreamingEnqueueClient, error)
	// Takes a set of op IDs and waits until those ops are done. Returns any error
	// in the stream so far.
	WaitQueueDone(ctx context.Context, in *WaitQueueDoneRequest, opts ...grpc.CallOption) (*WaitQueueDoneResponse, error)
	// Contexts are always created with a deadline and no RPCs within a deadline
	// will trigger a context garbage collection. KeepAlive calls can be used to
	// delay this. It can also be used to validate the existance of a context ID
	// on remote eager worker. If the context is on remote worker, return the same
	// ID and the current context view ID. This is useful for checking if the
	// remote worker (potentially with the same task name and hostname / port) is
	// replaced with a new process.
	KeepAlive(ctx context.Context, in *KeepAliveRequest, opts ...grpc.CallOption) (*KeepAliveResponse, error)
	// Closes the context. No calls to other methods using the existing context ID
	// are valid after this.
	CloseContext(ctx context.Context, in *CloseContextRequest, opts ...grpc.CallOption) (*CloseContextResponse, error)
}

type eagerServiceClient struct {
	cc *grpc.ClientConn
}

func NewEagerServiceClient(cc *grpc.ClientConn) EagerServiceClient {
	return &eagerServiceClient{cc}
}

func (c *eagerServiceClient) CreateContext(ctx context.Context, in *CreateContextRequest, opts ...grpc.CallOption) (*CreateContextResponse, error) {
	out := new(CreateContextResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/CreateContext", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *eagerServiceClient) UpdateContext(ctx context.Context, in *UpdateContextRequest, opts ...grpc.CallOption) (*UpdateContextResponse, error) {
	out := new(UpdateContextResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/UpdateContext", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *eagerServiceClient) Enqueue(ctx context.Context, in *EnqueueRequest, opts ...grpc.CallOption) (*EnqueueResponse, error) {
	out := new(EnqueueResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/Enqueue", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *eagerServiceClient) StreamingEnqueue(ctx context.Context, opts ...grpc.CallOption) (EagerService_StreamingEnqueueClient, error) {
	stream, err := c.cc.NewStream(ctx, &_EagerService_serviceDesc.Streams[0], "/tensorflow.eager.EagerService/StreamingEnqueue", opts...)
	if err != nil {
		return nil, err
	}
	x := &eagerServiceStreamingEnqueueClient{stream}
	return x, nil
}

type EagerService_StreamingEnqueueClient interface {
	Send(*EnqueueRequest) error
	Recv() (*EnqueueResponse, error)
	grpc.ClientStream
}

type eagerServiceStreamingEnqueueClient struct {
	grpc.ClientStream
}

func (x *eagerServiceStreamingEnqueueClient) Send(m *EnqueueRequest) error {
	return x.ClientStream.SendMsg(m)
}

func (x *eagerServiceStreamingEnqueueClient) Recv() (*EnqueueResponse, error) {
	m := new(EnqueueResponse)
	if err := x.ClientStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

func (c *eagerServiceClient) WaitQueueDone(ctx context.Context, in *WaitQueueDoneRequest, opts ...grpc.CallOption) (*WaitQueueDoneResponse, error) {
	out := new(WaitQueueDoneResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/WaitQueueDone", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *eagerServiceClient) KeepAlive(ctx context.Context, in *KeepAliveRequest, opts ...grpc.CallOption) (*KeepAliveResponse, error) {
	out := new(KeepAliveResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/KeepAlive", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *eagerServiceClient) CloseContext(ctx context.Context, in *CloseContextRequest, opts ...grpc.CallOption) (*CloseContextResponse, error) {
	out := new(CloseContextResponse)
	err := c.cc.Invoke(ctx, "/tensorflow.eager.EagerService/CloseContext", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// EagerServiceServer is the server API for EagerService service.
type EagerServiceServer interface {
	// This initializes the worker, informing it about the other workers in the
	// cluster and exchanging authentication tokens which will be used in all
	// other RPCs to detect whether the worker has restarted.
	CreateContext(context.Context, *CreateContextRequest) (*CreateContextResponse, error)
	// This updates the eager context on an existing worker when updating the set
	// of servers in a distributed eager cluster.
	UpdateContext(context.Context, *UpdateContextRequest) (*UpdateContextResponse, error)
	// This takes a list of Execute and DeleteTensorHandle operations and enqueues
	// (in async mode) or executes (in sync mode) them on the remote server.
	// All outputs of ops which were not explicitly deleted with
	// DeleteTensorHandle entries will be assumed to be alive and are usable by
	// future calls to Enqueue.
	Enqueue(context.Context, *EnqueueRequest) (*EnqueueResponse, error)
	// A streaming version of Enqueue.
	// Current server implementation sends one response per received request.
	// The benefit for using a streaming version is that subsequent requests
	// can be sent without waiting for a response to the previous request. This
	// synchronization is required in the regular Enqueue call because gRPC does
	// not guarantee to preserve request order.
	StreamingEnqueue(EagerService_StreamingEnqueueServer) error
	// Takes a set of op IDs and waits until those ops are done. Returns any error
	// in the stream so far.
	WaitQueueDone(context.Context, *WaitQueueDoneRequest) (*WaitQueueDoneResponse, error)
	// Contexts are always created with a deadline and no RPCs within a deadline
	// will trigger a context garbage collection. KeepAlive calls can be used to
	// delay this. It can also be used to validate the existance of a context ID
	// on remote eager worker. If the context is on remote worker, return the same
	// ID and the current context view ID. This is useful for checking if the
	// remote worker (potentially with the same task name and hostname / port) is
	// replaced with a new process.
	KeepAlive(context.Context, *KeepAliveRequest) (*KeepAliveResponse, error)
	// Closes the context. No calls to other methods using the existing context ID
	// are valid after this.
	CloseContext(context.Context, *CloseContextRequest) (*CloseContextResponse, error)
}

// UnimplementedEagerServiceServer can be embedded to have forward compatible implementations.
type UnimplementedEagerServiceServer struct {
}

func (*UnimplementedEagerServiceServer) CreateContext(ctx context.Context, req *CreateContextRequest) (*CreateContextResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method CreateContext not implemented")
}
func (*UnimplementedEagerServiceServer) UpdateContext(ctx context.Context, req *UpdateContextRequest) (*UpdateContextResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method UpdateContext not implemented")
}
func (*UnimplementedEagerServiceServer) Enqueue(ctx context.Context, req *EnqueueRequest) (*EnqueueResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method Enqueue not implemented")
}
func (*UnimplementedEagerServiceServer) StreamingEnqueue(srv EagerService_StreamingEnqueueServer) error {
	return status.Errorf(codes.Unimplemented, "method StreamingEnqueue not implemented")
}
func (*UnimplementedEagerServiceServer) WaitQueueDone(ctx context.Context, req *WaitQueueDoneRequest) (*WaitQueueDoneResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method WaitQueueDone not implemented")
}
func (*UnimplementedEagerServiceServer) KeepAlive(ctx context.Context, req *KeepAliveRequest) (*KeepAliveResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method KeepAlive not implemented")
}
func (*UnimplementedEagerServiceServer) CloseContext(ctx context.Context, req *CloseContextRequest) (*CloseContextResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method CloseContext not implemented")
}

func RegisterEagerServiceServer(s *grpc.Server, srv EagerServiceServer) {
	s.RegisterService(&_EagerService_serviceDesc, srv)
}

func _EagerService_CreateContext_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(CreateContextRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).CreateContext(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/CreateContext",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).CreateContext(ctx, req.(*CreateContextRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _EagerService_UpdateContext_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(UpdateContextRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).UpdateContext(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/UpdateContext",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).UpdateContext(ctx, req.(*UpdateContextRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _EagerService_Enqueue_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(EnqueueRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).Enqueue(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/Enqueue",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).Enqueue(ctx, req.(*EnqueueRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _EagerService_StreamingEnqueue_Handler(srv interface{}, stream grpc.ServerStream) error {
	return srv.(EagerServiceServer).StreamingEnqueue(&eagerServiceStreamingEnqueueServer{stream})
}

type EagerService_StreamingEnqueueServer interface {
	Send(*EnqueueResponse) error
	Recv() (*EnqueueRequest, error)
	grpc.ServerStream
}

type eagerServiceStreamingEnqueueServer struct {
	grpc.ServerStream
}

func (x *eagerServiceStreamingEnqueueServer) Send(m *EnqueueResponse) error {
	return x.ServerStream.SendMsg(m)
}

func (x *eagerServiceStreamingEnqueueServer) Recv() (*EnqueueRequest, error) {
	m := new(EnqueueRequest)
	if err := x.ServerStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

func _EagerService_WaitQueueDone_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(WaitQueueDoneRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).WaitQueueDone(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/WaitQueueDone",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).WaitQueueDone(ctx, req.(*WaitQueueDoneRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _EagerService_KeepAlive_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(KeepAliveRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).KeepAlive(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/KeepAlive",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).KeepAlive(ctx, req.(*KeepAliveRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _EagerService_CloseContext_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(CloseContextRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(EagerServiceServer).CloseContext(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/tensorflow.eager.EagerService/CloseContext",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(EagerServiceServer).CloseContext(ctx, req.(*CloseContextRequest))
	}
	return interceptor(ctx, in, info, handler)
}

var _EagerService_serviceDesc = grpc.ServiceDesc{
	ServiceName: "tensorflow.eager.EagerService",
	HandlerType: (*EagerServiceServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "CreateContext",
			Handler:    _EagerService_CreateContext_Handler,
		},
		{
			MethodName: "UpdateContext",
			Handler:    _EagerService_UpdateContext_Handler,
		},
		{
			MethodName: "Enqueue",
			Handler:    _EagerService_Enqueue_Handler,
		},
		{
			MethodName: "WaitQueueDone",
			Handler:    _EagerService_WaitQueueDone_Handler,
		},
		{
			MethodName: "KeepAlive",
			Handler:    _EagerService_KeepAlive_Handler,
		},
		{
			MethodName: "CloseContext",
			Handler:    _EagerService_CloseContext_Handler,
		},
	},
	Streams: []grpc.StreamDesc{
		{
			StreamName:    "StreamingEnqueue",
			Handler:       _EagerService_StreamingEnqueue_Handler,
			ServerStreams: true,
			ClientStreams: true,
		},
	},
	Metadata: "github.com/smoug25/tensorflow_serving_helper/tensorflow/core/protobuf/eager_service.proto",
}
